{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_7SVmxnE9xS"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# import kagglehub\n",
        "# !kaggle datasets download -d adejumobidaniel/seq2seq-dataset\n",
        "# !unzip /content/seq2seq-dataset.zip -d main_data\n",
        "\n",
        "# import json\n",
        "\n",
        "# with open('fr_str2int.json', 'w') as f:\n",
        "#     json.dump(fr_str2int, f)\n",
        "\n",
        "# with open('fr_int2str.json', 'w') as f:\n",
        "#     json.dump(fr_int2str, f)\n",
        "\n",
        "# with open('en_str2int.json', 'w') as f:\n",
        "#     json.dump(en_str2int, f)\n",
        "\n",
        "# with open('en_int2str.json', 'w') as f:\n",
        "#     json.dump(en_int2str, f)\n",
        "\n",
        "# !cp -r /content/main_data /content/drive/MyDrive\n",
        "# !cp /content/en_int2str.json /content/drive/MyDrive/main_data\n",
        "# !cp /content/en_str2int.json /content/drive/MyDrive/main_data\n",
        "# !cp /content/fr_int2str.json /content/drive/MyDrive/main_data\n",
        "# !cp /content/fr_str2int.json /content/drive/MyDrive/main_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxZsMWwLQgbG",
        "outputId": "af279d1f-8942-4d20-df78-67697cef960c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xv9kru13DChq",
        "outputId": "840d23cb-11dc-4212-da17-c57fc3b15a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install datasets -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ktA5a75DChu"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "import json\n",
        "\n",
        "dataset_train = load_from_disk ('/content/drive/MyDrive/main_data/dataset_train')\n",
        "dataset_test = load_from_disk ('/content/drive/MyDrive/main_data/dataset_test')\n",
        "dataset_validation = load_from_disk ('/content/drive/MyDrive/main_data/dataset_validation')\n",
        "\n",
        "with open('/content/drive/MyDrive/main_data/en_int2str.json', 'r') as f:\n",
        "    en_int2str = json.load(f)\n",
        "with open('/content/drive/MyDrive/main_data/en_str2int.json', 'r') as f:\n",
        "    en_str2int = json.load(f)\n",
        "with open('/content/drive/MyDrive/main_data/fr_int2str.json', 'r') as f:\n",
        "    fr_int2str = json.load(f)\n",
        "with open('/content/drive/MyDrive/main_data/fr_str2int.json', 'r') as f:\n",
        "    fr_str2int = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP7xfM9FDChx",
        "outputId": "74196c6e-419e-4a90-847b-00e76b8a9f56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([7, 32]), torch.Size([24, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# data batching\n",
        "def get_collate_fn(pad_index):\n",
        "    def collate_fn(batch):\n",
        "        batch_en_ids = [example['en_ids'] for example in batch]\n",
        "        batch_fr_ids = [example['fr_ids'] for example in batch]\n",
        "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
        "        batch_fr_ids = nn.utils.rnn.pad_sequence(batch_fr_ids, padding_value=pad_index)\n",
        "        batch = {\n",
        "            'en_ids': batch_en_ids,\n",
        "            'fr_ids': batch_fr_ids\n",
        "        }\n",
        "        return batch\n",
        "    return collate_fn\n",
        "\n",
        "\n",
        "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
        "    collate_fn = get_collate_fn(pad_index)\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        shuffle=shuffle\n",
        "    )\n",
        "    return data_loader\n",
        "\n",
        "sos_token = '<sos>'\n",
        "eos_token = '<eos>'\n",
        "pad_token = '<pad>'\n",
        "\n",
        "batch_size = 32 #128\n",
        "PAD_INDEX = en_str2int[pad_token]\n",
        "\n",
        "train_data_loader = get_data_loader(dataset_train, batch_size, PAD_INDEX, shuffle=False)\n",
        "test_data_loader = get_data_loader(dataset_test, batch_size, PAD_INDEX, shuffle=False)\n",
        "validation_data_loader = get_data_loader(dataset_validation, batch_size, PAD_INDEX, shuffle=False)\n",
        "\n",
        "result = next(iter(train_data_loader))\n",
        "result['en_ids'].shape, result['fr_ids'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dAT52odaDChy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, embedding_dim, hidden_dim, num_layers):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, input_, hidden, cell):\n",
        "        input_ = input_.unsqueeze(0)\n",
        "        embedded = self.embedding(input_)\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, trg_len):\n",
        "        '''\n",
        "        src: [src_len, batch_size]\n",
        "        trg: [trg_len, batch_size]\n",
        "        trg_len: length o\n",
        "        '''\n",
        "        batch_size = src.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        input_ = trg[0, :]\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input_, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input_ = top1\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L4Nuy4zbDCh0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "model hyperparameters\n",
        "'''\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "input_dim = len(en_str2int)\n",
        "output_dim = len(fr_str2int)\n",
        "\n",
        "encoder_embedding_dim = 50 #1_000\n",
        "decoder_embedding_dim = 50 #1_000\n",
        "\n",
        "hidden_dim = 50 # 1_000\n",
        "num_layers = 1 # 4\n",
        "\n",
        "\n",
        "encoder = Encoder(\n",
        "    input_dim,\n",
        "    encoder_embedding_dim,\n",
        "    hidden_dim,\n",
        "    num_layers,\n",
        ").to(device)\n",
        "\n",
        "decoder = Decoder(\n",
        "    output_dim,\n",
        "    decoder_embedding_dim,\n",
        "    hidden_dim,\n",
        "    num_layers,\n",
        ").to(device)\n",
        "\n",
        "\n",
        "'''\n",
        "The paper suggest that initialzing the weight with a uniform distribution of -0.08 to 0.08\n",
        "'''\n",
        "for param in encoder.parameters():\n",
        "    torch.nn.init.uniform_(param, a=-0.08, b=0.08)\n",
        "\n",
        "for param in decoder.parameters():\n",
        "    torch.nn.init.uniform_(param, a=-0.08, b=0.08)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "# model = nn.DataParallel(model, device_ids=[1, 2])\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=fr_str2int['<pad>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aoB2YYxGDCh1"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        src = batch['en_ids'].to(device)\n",
        "        trg = batch['fr_ids'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, trg.shape[0]).to(device)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        for param in model.parameters():\n",
        "            param.grad /= batch_size\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QnesJJdeDCh2"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            src = batch['en_ids'].to(device)\n",
        "            trg = batch['fr_ids'].to(device)\n",
        "\n",
        "            output = model(src, trg, trg.shape[0])\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    mins = int(elapsed_time / 60)\n",
        "    secs = int(elapsed_time - (mins * 60))\n",
        "    return mins, secs\n",
        "\n",
        "N_EPOCHS = 7.5\n",
        "initial_lr = 0.7\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=initial_lr, momentum=0)\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    if epoch >= 5:\n",
        "        factor = 2 ** ((epoch - 5) * 2)  # Halving every half epoch\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = initial_lr / factor  # Decay learning rate\n",
        "\n",
        "total_half_epochs = int(N_EPOCHS * 2)\n",
        "\n",
        "\n",
        "for i in range(total_half_epochs):\n",
        "  current_epoch = i / 2\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  if current_epoch >= 5:\n",
        "      adjust_learning_rate(optimizer, current_epoch)\n",
        "  current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "                            # train_data_loader\n",
        "  train_loss = train(model, test_data_loader, optimizer, criterion) # currently replaced with test_data_loader.\n",
        "  valid_loss = evaluate(model, validation_data_loader, criterion)\n",
        "\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  print(f\"Epoch {current_epoch:.1f}: | Learning Rate = {current_lr:.5f} | Time: {epoch_mins}m {epoch_secs}s\")\n",
        "  print(f\"\\tTrain Loss: {train_loss:.3f}\")\n",
        "  print(f\"\\tVal. Loss: {valid_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb8rrNGy9eoq",
        "outputId": "3b1b9c3d-413d-492a-df12-5e066e0da6d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0.0: | Learning Rate = 0.70000 | Time: 2m 51s\n",
            "\tTrain Loss: 11.913\n",
            "\tVal. Loss: 11.899\n",
            "Epoch 0.5: | Learning Rate = 0.70000 | Time: 2m 42s\n",
            "\tTrain Loss: 11.887\n",
            "\tVal. Loss: 11.872\n",
            "Epoch 1.0: | Learning Rate = 0.70000 | Time: 2m 41s\n",
            "\tTrain Loss: 11.861\n",
            "\tVal. Loss: 11.844\n",
            "Epoch 1.5: | Learning Rate = 0.70000 | Time: 2m 42s\n",
            "\tTrain Loss: 11.833\n",
            "\tVal. Loss: 11.815\n",
            "Epoch 2.0: | Learning Rate = 0.70000 | Time: 2m 42s\n",
            "\tTrain Loss: 11.804\n",
            "\tVal. Loss: 11.785\n",
            "Epoch 2.5: | Learning Rate = 0.70000 | Time: 2m 42s\n",
            "\tTrain Loss: 11.774\n",
            "\tVal. Loss: 11.753\n",
            "Epoch 3.0: | Learning Rate = 0.70000 | Time: 2m 41s\n",
            "\tTrain Loss: 11.740\n",
            "\tVal. Loss: 11.716\n",
            "Epoch 3.5: | Learning Rate = 0.70000 | Time: 2m 41s\n",
            "\tTrain Loss: 11.703\n",
            "\tVal. Loss: 11.675\n",
            "Epoch 4.0: | Learning Rate = 0.70000 | Time: 2m 41s\n",
            "\tTrain Loss: 11.659\n",
            "\tVal. Loss: 11.626\n",
            "Epoch 4.5: | Learning Rate = 0.70000 | Time: 2m 41s\n",
            "\tTrain Loss: 11.605\n",
            "\tVal. Loss: 11.565\n",
            "Epoch 5.0: | Learning Rate = 0.70000 | Time: 2m 41s\n",
            "\tTrain Loss: 11.536\n",
            "\tVal. Loss: 11.484\n",
            "Epoch 5.5: | Learning Rate = 0.35000 | Time: 2m 42s\n",
            "\tTrain Loss: 11.470\n",
            "\tVal. Loss: 11.432\n",
            "Epoch 6.0: | Learning Rate = 0.17500 | Time: 2m 41s\n",
            "\tTrain Loss: 11.429\n",
            "\tVal. Loss: 11.402\n",
            "Epoch 6.5: | Learning Rate = 0.08750 | Time: 2m 42s\n",
            "\tTrain Loss: 11.406\n",
            "\tVal. Loss: 11.386\n",
            "Epoch 7.0: | Learning Rate = 0.04375 | Time: 2m 41s\n",
            "\tTrain Loss: 11.394\n",
            "\tVal. Loss: 11.378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search_decoder(model, src, beam_width=5, max_len=None):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src)\n",
        "\n",
        "        hidden = hidden.squeeze(1)\n",
        "        cell = cell.squeeze(1)\n",
        "\n",
        "        # Use French SOS token since decoder works with French tokens.\n",
        "        start_token = torch.tensor([fr_str2int['<sos>']], device=device)\n",
        "        sequences = [(start_token, 0, hidden, cell)]\n",
        "\n",
        "        # Dynamically set maximum output length based on the source sequence length.\n",
        "        if max_len is None:\n",
        "            max_len = src.size(0) * 2  # or any multiplier suitable for your task\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            all_candidates = []\n",
        "            for seq, score, h, c in sequences:\n",
        "                # Feed the last token of the current sequence.\n",
        "                output, h_new, c_new = model.decoder(seq[-1], h, c)\n",
        "                top_k_probs, top_k_words = torch.topk(output, beam_width)\n",
        "\n",
        "                for i in range(beam_width):\n",
        "                    # Extend the sequence with the i-th candidate.\n",
        "                    new_seq = torch.cat((seq, top_k_words[i].unsqueeze(0)))\n",
        "                    new_score = score + torch.log(top_k_probs[i])\n",
        "                    all_candidates.append((new_seq, new_score, h_new, c_new))\n",
        "\n",
        "            # Keep only the best beam_width sequences.\n",
        "            sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "\n",
        "            # If the best sequence ends with EOS, break early.\n",
        "            if sequences[0][0][-1].item() == fr_str2int['<eos>']:\n",
        "                break\n",
        "\n",
        "        return sequences[0][0]"
      ],
      "metadata": {
        "id": "Vk3qYCH14Sor"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "--J_3jF9DCh5"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(model, sentence, en_str2int, fr_int2str, beam_width=5, max_len=None):\n",
        "    \"\"\"\n",
        "    Translate a source sentence using beam search.\n",
        "    - sentence: a string (or list) of tokens in the source language.\n",
        "    - en_str2int: dictionary mapping source tokens to indices.\n",
        "    - fr_int2str: dictionary mapping target indices to tokens.\n",
        "    - beam_width: beam width to use during decoding.\n",
        "    - max_len: maximum output length; if None, it is set dynamically.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize and convert sentence to indices.\n",
        "    tokens = sentence.strip().split()  # Simple whitespace split; adjust as needed.\n",
        "    # Prepend SOS if needed (depends on how you encoded your training data).\n",
        "    src_indices = [en_str2int['<sos>']] + [en_str2int.get(token, en_str2int['<pad>']) for token in tokens] + [en_str2int['<eos>']]\n",
        "    src_tensor = torch.LongTensor(src_indices).unsqueeze(1).to(device)  # Shape: [src_len, 1]\n",
        "    print(src_tensor.shape)\n",
        "    # Run beam search decoder.\n",
        "    output_indices = beam_search_decoder(model, src_tensor, beam_width, max_len)\n",
        "\n",
        "    # Convert output indices to tokens.\n",
        "    # Optionally, remove the SOS and EOS tokens from the output.\n",
        "    # Handle unknown tokens by replacing them with <unk>.\n",
        "    output_tokens = [fr_int2str.get(idx.item(), '<unk>') for idx in output_indices]\n",
        "    return output_tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = \"this is a test\"\n",
        "translated_tokens = translate_sentence(model, sample_sentence, en_str2int, fr_int2str, beam_width=12)\n",
        "print(\"Translated:\", \" \".join(translated_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfMNyOU67G5v",
        "outputId": "bc21ecc8-d2ac-4ffd-b4a6-e3c8cce4e570"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 1])\n",
            "Translated: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "ICppX_TTViiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
        "\n",
        "def calculate_bleu(data, model, device, max_len=50):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "\n",
        "    for datum in data:\n",
        "        src = datum['en_ids']\n",
        "        trg = datum['fr_ids']\n",
        "\n",
        "        src_sentence = src.tolist()[0]\n",
        "        trg_sentence = trg.tolist()[0]\n",
        "\n",
        "        pred_tokens = translate_sentence(src_sentence, model.encoder, model.decoder, en_str2int, fr_str2int, device, max_len)\n",
        "        pred_tokens = pred_tokens[1:-1]  # Remove <sos> and <eos>\n",
        "\n",
        "        trg_tokens = [int2fr[token] for token in trg_sentence if token not in [fr_str2int['<sos>'], fr_str2int['<eos>'], fr_str2int['<pad>']]]\n",
        "\n",
        "        trgs.append([trg_tokens])\n",
        "        pred_trgs.append(pred_tokens)\n",
        "\n",
        "    return corpus_bleu(trgs, pred_trgs)\n",
        "\n",
        "calculate_bleu(validation_data_loader, model, device=device)"
      ],
      "metadata": {
        "id": "zh9AhawuKxlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and load model"
      ],
      "metadata": {
        "id": "hZGHzcS_Taac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"torch.save({\n",
        "    'encoder_state_dict': encoder.state_dict(),\n",
        "    'decoder_state_dict': decoder.state_dict(),\n",
        "}, 'seq2seq_model.pth')\n",
        "\n",
        "checkpoint = torch.load('seq2seq_model.pth')\n",
        "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
        "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "model.eval()\"\"\""
      ],
      "metadata": {
        "id": "Bb6u29ZHVPY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/main_data/model_weights.pth')"
      ],
      "metadata": {
        "id": "cALL2GgOTcKr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model__ = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "\n",
        "model__.load_state_dict(torch.load('/content/drive/MyDrive/main_data/model_weights.pth', weights_only=True))\n",
        "model__.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBu6z5LfTfwT",
        "outputId": "f9eee57e-b03f-4f8c-bdc7-163a63b07dde"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(126272, 50)\n",
              "    (rnn): LSTM(50, 50)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(150345, 50)\n",
              "    (rnn): LSTM(50, 50)\n",
              "    (fc_out): Linear(in_features=50, out_features=150345, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = \"this is a test\"\n",
        "translated_tokens = translate_sentence(model__, sample_sentence, en_str2int, fr_int2str, beam_width=12)\n",
        "print(\"Translated:\", \" \".join(translated_tokens))"
      ],
      "metadata": {
        "id": "8QllSFT0T-O3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 6574858,
          "sourceId": 10619101,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30840,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}